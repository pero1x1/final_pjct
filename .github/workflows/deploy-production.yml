name: deploy-production

on:
  push:
    tags: ["v*"]
  workflow_dispatch:
    inputs:
      cluster_id:
        description: "Override K8s cluster id (optional)"
        required: false
      namespace:
        description: "Kubernetes namespace"
        required: true
        default: "credit-scoring"

permissions:
  contents: read

jobs:
  deploy:
    environment: production
    # If K8s API is not reachable from GitHub-hosted runners, set repo variable DEPLOY_RUNNER=self-hosted.
    runs-on: ${{ vars.DEPLOY_RUNNER || 'ubuntu-latest' }}

    env:
      NAMESPACE: ${{ github.event.inputs.namespace || 'credit-scoring' }}
      CLUSTER_ID: ${{ github.event.inputs.cluster_id || secrets.YC_K8S_CLUSTER_ID_STAGING }}
      REGISTRY_ID: ${{ secrets.YC_REGISTRY_ID }}
      BACKEND_IMAGE: cr.yandex/${{ secrets.YC_REGISTRY_ID }}/credit-backend:${{ github.sha }}
      FRONTEND_IMAGE: cr.yandex/${{ secrets.YC_REGISTRY_ID }}/credit-frontend:${{ github.sha }}

    steps:
      - uses: actions/checkout@v4

      - name: Validate required secrets
        shell: bash
        env:
          YC_SA_KEY_JSON: ${{ secrets.YC_SA_KEY_JSON }}
          YC_REGISTRY_ID: ${{ secrets.YC_REGISTRY_ID }}
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
        run: |
          set -euo pipefail
          for k in YC_SA_KEY_JSON YC_REGISTRY_ID S3_ACCESS_KEY_ID S3_SECRET_ACCESS_KEY; do
            if [ -z "${!k:-}" ]; then
              echo "ERROR: secret $k is empty or not set"
              exit 1
            fi
          done
          if [ -z "${CLUSTER_ID:-}" ]; then
            echo "ERROR: CLUSTER_ID is empty (set input cluster_id or secret YC_K8S_CLUSTER_ID_STAGING)"
            exit 1
          fi

      - name: Install YC CLI
        shell: bash
        run: |
          curl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash -s -- -n
          export PATH="$HOME/yandex-cloud/bin:$PATH"
          yc --version
          echo "$HOME/yandex-cloud/bin" >> $GITHUB_PATH

      - name: Configure YC CLI (service account)
        shell: bash
        env:
          YC_SA_KEY_JSON: ${{ secrets.YC_SA_KEY_JSON }}
        run: |
          set -euo pipefail
          if [ -z "${YC_SA_KEY_JSON:-}" ]; then
            echo "ERROR: secret YC_SA_KEY_JSON is empty or not set"
            exit 1
          fi

          # Accept either raw JSON or base64-encoded JSON
          if printf '%s' "$YC_SA_KEY_JSON" | head -c 1 | grep -q '{'; then
            printf '%s' "$YC_SA_KEY_JSON" > sa-key.json
          else
            printf '%s' "$YC_SA_KEY_JSON" | base64 -d > sa-key.json
          fi

          echo "sa-key.json size: $(wc -c < sa-key.json) bytes"
          python3 - <<'PY'
          import json
          with open("sa-key.json", "r", encoding="utf-8") as f:
            json.load(f)
          print("sa-key.json is valid JSON")
          PY

          yc config profile create ci 2>/dev/null || true
          yc config set service-account-key sa-key.json --profile ci
          yc config profile activate ci
          rm -f sa-key.json

      - name: Configure Docker for YCR
        run: yc container registry configure-docker

      - uses: docker/setup-buildx-action@v3

      - name: Build & push backend (YCR)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: docker/backend/Dockerfile
          push: true
          tags: |
            cr.yandex/${{ secrets.YC_REGISTRY_ID }}/credit-backend:${{ github.sha }}

      - name: Build & push frontend (YCR)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: docker/frontend/Dockerfile
          push: true
          tags: |
            cr.yandex/${{ secrets.YC_REGISTRY_ID }}/credit-frontend:${{ github.sha }}

      - name: Set up kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: "v1.32.1"

      - name: Get kubeconfig (production)
        run: yc managed-kubernetes cluster get-credentials --id "$CLUSTER_ID" --external --force

      - name: Deploy + monitor + rollback on failure
        shell: bash
        env:
          S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
        run: |
          set -euo pipefail

          k() { kubectl --request-timeout=180s "$@"; }

          rollback() {
            echo "Deploy failed -> rollback..."
            k -n "$NAMESPACE" rollout undo deployment/backend || true
            k -n "$NAMESPACE" rollout undo deployment/frontend || true
            k -n "$NAMESPACE" get pods -o wide || true
            k -n "$NAMESPACE" logs deploy/backend -c dvc-pull --tail=200 || true
          }
          trap rollback ERR

          k apply --validate=false -f k8s/00-namespace.yaml
          k apply --validate=false -f k8s/10-configmap-backend.yaml

          k -n "$NAMESPACE" create secret generic s3-credentials \
            --from-literal=AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY_ID" \
            --from-literal=AWS_SECRET_ACCESS_KEY="$S3_SECRET_ACCESS_KEY" \
            --dry-run=client -o yaml | k apply --validate=false -f -

          k apply --validate=false -f k8s/21-svc-backend.yaml
          k apply --validate=false -f k8s/31-svc-frontend.yaml
          k apply --validate=false -f k8s/20-deploy-backend.yaml
          k apply --validate=false -f k8s/30-deploy-frontend.yaml
          k apply --validate=false -f k8s/40-ingress.yaml

          k -n "$NAMESPACE" set image deployment/backend \
            backend="$BACKEND_IMAGE" dvc-pull="$BACKEND_IMAGE"
          k -n "$NAMESPACE" set image deployment/frontend \
            frontend="$FRONTEND_IMAGE"

          k -n "$NAMESPACE" rollout status deployment/backend --timeout=300s
          k -n "$NAMESPACE" rollout status deployment/frontend --timeout=300s

          echo "Port-forward frontend and check /api/health + /api/docs..."
          kubectl -n "$NAMESPACE" port-forward svc/frontend-svc 8080:80 --address 127.0.0.1 >/tmp/pf.log 2>&1 &
          PF_PID=$!
          trap 'kill "$PF_PID" 2>/dev/null || true' EXIT

          for _ in {1..30}; do
            if grep -q "Forwarding from" /tmp/pf.log; then
              break
            fi
            if ! kill -0 "$PF_PID" 2>/dev/null; then
              echo "port-forward exited early:"
              cat /tmp/pf.log || true
              exit 1
            fi
            sleep 1
          done

          if ! grep -q "Forwarding from" /tmp/pf.log; then
            echo "port-forward did not become ready:"
            cat /tmp/pf.log || true
            exit 1
          fi

          curl -fsS --retry 10 --retry-connrefused --retry-delay 1 "http://127.0.0.1:8080/api/health"
          curl -fsS --retry 10 --retry-connrefused --retry-delay 1 "http://127.0.0.1:8080/api/docs" | head -c 200
